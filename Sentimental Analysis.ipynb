{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentimental Analysis of Text Data : Neutral and Negative\n",
    "\n",
    "by Jahnavi Mishra\n",
    "\n",
    "Tech Stack:\n",
    "1. Python Programming Language\n",
    "2. Natural Language Processing\n",
    "3. Machine Learning Classifiers\n",
    "\n",
    "Steps:\n",
    "1. Data Cleaning and Pre Processing\n",
    "2. EDA and Visualization ( in another file)\n",
    "3. Feature Extraction\n",
    "4. Sampling\n",
    "5. Model Building and Training Phase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import math\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2a0463352b</td>\n",
       "      <td>that`s enough! I`ll do nothing for 2 hours.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f358968122</td>\n",
       "      <td>I have to go clothes shopping tomorrow  I hate...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>449e7733f1</td>\n",
       "      <td>i am bored. :| any idea`s of a nice site?</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6099baf6e8</td>\n",
       "      <td>I don`t think  will want to come back  (guys r...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f946da7a04</td>\n",
       "      <td>_thomas if only the drinking game was tonight....</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text sentiment\n",
       "0  2a0463352b        that`s enough! I`ll do nothing for 2 hours.   neutral\n",
       "1  f358968122  I have to go clothes shopping tomorrow  I hate...  negative\n",
       "2  449e7733f1          i am bored. :| any idea`s of a nice site?   neutral\n",
       "3  6099baf6e8  I don`t think  will want to come back  (guys r...  negative\n",
       "4  f946da7a04  _thomas if only the drinking game was tonight....   neutral"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Dataset from - https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection\n",
    "df = pd.read_csv('sentiments.csv',\n",
    "                   header=None,\n",
    "                   names=['textID', 'text', 'sentiment'])\n",
    "\n",
    "# Printing out first 5 columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18899 entries, 0 to 18898\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   textID     18899 non-null  object\n",
      " 1   text       18898 non-null  object\n",
      " 2   sentiment  18899 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 443.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textID       0\n",
       "text         1\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     11118\n",
       "negative     7781\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textID       0\n",
       "text         0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.dropna()\n",
    "df1.isnull().sum().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['that`s enough! I`ll do nothing for 2 hours.',\n",
       "       \"I have to go clothes shopping tomorrow  I hate it, but I have a serious 'clothes falling apart' situation here.\",\n",
       "       'i am bored. :| any idea`s of a nice site?', ...,\n",
       "       'Last night in Australia', 'painting',\n",
       "       'Is in bed not able to sleep  bloody bipolar!'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['text'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning Phase:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Expanding Contractions: Eg. can't becomes can not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of English Contractions\n",
    "import re\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "contractions_dict = { \"ain't\": \"are not\",\"'s\":\" is\",\"aren't\": \"are not\",\n",
    "                     \"can't\": \"cannot\",\"can't've\": \"cannot have\",\n",
    "                     \"'cause\": \"because\",\"could've\": \"could have\",\"couldn't\": \"could not\",\n",
    "                     \"couldn't've\": \"could not have\", \"didn't\": \"did not\",\"doesn't\": \"does not\",\n",
    "                     \"don't\": \"do not\",\"hadn't\": \"had not\",\"hadn't've\": \"had not have\",\n",
    "                     \"hasn't\": \"has not\",\"haven't\": \"have not\",\"he'd\": \"he would\",\n",
    "                     \"he'd've\": \"he would have\",\"he'll\": \"he will\", \"he'll've\": \"he will have\",\n",
    "                     \"how'd\": \"how did\",\"how'd'y\": \"how do you\",\"how'll\": \"how will\",\n",
    "                     \"I'd\": \"I would\", \"I'd've\": \"I would have\",\"I'll\": \"I will\",\n",
    "                     \"I'll've\": \"I will have\",\"I'm\": \"I am\",\"I've\": \"I have\", \"isn't\": \"is not\",\n",
    "                     \"it'd\": \"it would\",\"it'd've\": \"it would have\",\"it'll\": \"it will\",\n",
    "                     \"it'll've\": \"it will have\", \"let's\": \"let us\",\"ma'am\": \"madam\",\n",
    "                     \"mayn't\": \"may not\",\"might've\": \"might have\",\"mightn't\": \"might not\", \n",
    "                     \"mightn't've\": \"might not have\",\"must've\": \"must have\",\"mustn't\": \"must not\",\n",
    "                     \"mustn't've\": \"must not have\", \"needn't\": \"need not\",\n",
    "                     \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\"oughtn't\": \"ought not\",\n",
    "                     \"oughtn't've\": \"ought not have\",\"shan't\": \"shall not\",\"sha'n't\": \"shall not\",\n",
    "                     \"shan't've\": \"shall not have\",\"she'd\": \"she would\",\"she'd've\": \"she would have\",\n",
    "                     \"she'll\": \"she will\", \"she'll've\": \"she will have\",\"should've\": \"should have\",\n",
    "                     \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\",\"so've\": \"so have\",\n",
    "                     \"that'd\": \"that would\",\"that'd've\": \"that would have\", \"there'd\": \"there would\",\n",
    "                     \"there'd've\": \"there would have\", \"they'd\": \"they would\",\n",
    "                     \"they'd've\": \"they would have\",\"they'll\": \"they will\",\n",
    "                     \"they'll've\": \"they will have\", \"they're\": \"they are\",\"they've\": \"they have\",\n",
    "                     \"to've\": \"to have\",\"wasn't\": \"was not\",\"we'd\": \"we would\",\n",
    "                     \"we'd've\": \"we would have\",\"we'll\": \"we will\",\"we'll've\": \"we will have\",\n",
    "                     \"we're\": \"we are\",\"we've\": \"we have\", \"weren't\": \"were not\",\"what'll\": \"what will\",\n",
    "                     \"what'll've\": \"what will have\",\"what're\": \"what are\", \"what've\": \"what have\",\n",
    "                     \"when've\": \"when have\",\"where'd\": \"where did\", \"where've\": \"where have\",\n",
    "                     \"who'll\": \"who will\",\"who'll've\": \"who will have\",\"who've\": \"who have\",\n",
    "                     \"why've\": \"why have\",\"will've\": \"will have\",\"won't\": \"will not\",\n",
    "                     \"won't've\": \"will not have\", \"would've\": \"would have\",\"wouldn't\": \"would not\",\n",
    "                     \"wouldn't've\": \"would not have\",\"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
    "                     \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\n",
    "                     \"y'all've\": \"you all have\", \"you'd\": \"you would\",\"you'd've\": \"you would have\",\n",
    "                     \"you'll\": \"you will\",\"you'll've\": \"you will have\", \"you're\": \"you are\",\n",
    "                     \"you've\": \"you have\"}\n",
    "\n",
    "# Regular expression for finding contractions\n",
    "contractions_re=re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
    "\n",
    "# Function for expanding contractions\n",
    "def expand_contractions(text,contractions_dict=contractions_dict):\n",
    "  def replace(match):\n",
    "    return contractions_dict[match.group(0)]\n",
    "  return contractions_re.sub(replace, text)\n",
    "\n",
    "# Expanding Contractions in the reviews\n",
    "df1['text']=df1['text'].apply(lambda x:expand_contractions(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Converting the text to lower case: for uniformity as in NLP, Hello and hEllO are treated as different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['cleaned']=df1['text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Removing digits and numbers and characters from the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['cleaned']=df1['cleaned'].apply(lambda x: re.sub('\\w*\\d\\w*','', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Removing punctuations from the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['cleaned']=df1['cleaned'].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Removing extra spaces from the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['cleaned']=df1['cleaned'].apply(lambda x: re.sub(' +',' ',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text 1:\n",
      " my mom wants to lay well be there later probably a little after and im sorry youre sick\n",
      "text 2:\n",
      " sometimes knowledge is not a good thing httpdiggcom\n",
      "text 3:\n",
      "  me and my moms cars were broken into i feel violated\n",
      "text 4:\n",
      " we are going all out\n",
      "text 5:\n",
      " m do it up\n"
     ]
    }
   ],
   "source": [
    "for index,text in enumerate(df1['cleaned'][35:40]):\n",
    "  print('text %d:\\n'%(index+1),text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Label Encoding: For binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18898, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2a0463352b</td>\n",
       "      <td>that`s enough! I`ll do nothing for 2 hours.</td>\n",
       "      <td>1</td>\n",
       "      <td>thats enough ill do nothing for hours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f358968122</td>\n",
       "      <td>I have to go clothes shopping tomorrow  I hate...</td>\n",
       "      <td>0</td>\n",
       "      <td>i have to go clothes shopping tomorrow i hate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>449e7733f1</td>\n",
       "      <td>i am bored. :| any idea`s of a nice site?</td>\n",
       "      <td>1</td>\n",
       "      <td>i am bored any ideas of a nice site</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6099baf6e8</td>\n",
       "      <td>I don`t think  will want to come back  (guys r...</td>\n",
       "      <td>0</td>\n",
       "      <td>i dont think will want to come back guys read ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f946da7a04</td>\n",
       "      <td>_thomas if only the drinking game was tonight....</td>\n",
       "      <td>1</td>\n",
       "      <td>thomas if only the drinking game was tonighti ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  sentiment  \\\n",
       "0  2a0463352b        that`s enough! I`ll do nothing for 2 hours.          1   \n",
       "1  f358968122  I have to go clothes shopping tomorrow  I hate...          0   \n",
       "2  449e7733f1          i am bored. :| any idea`s of a nice site?          1   \n",
       "3  6099baf6e8  I don`t think  will want to come back  (guys r...          0   \n",
       "4  f946da7a04  _thomas if only the drinking game was tonight....          1   \n",
       "\n",
       "                                             cleaned  \n",
       "0              thats enough ill do nothing for hours  \n",
       "1  i have to go clothes shopping tomorrow i hate ...  \n",
       "2                i am bored any ideas of a nice site  \n",
       "3  i dont think will want to come back guys read ...  \n",
       "4  thomas if only the drinking game was tonighti ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing 'negative' to 0 and 'neutral' to 1\n",
    "df1['sentiment'] = df1.sentiment.map({'negative':0, 'neutral':1})\n",
    "\n",
    "# Get an idea of the size of the dataset\n",
    "print(df1.shape)\n",
    "\n",
    "# Previewing\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1= df1.drop(['textID', 'text'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>thats enough ill do nothing for hours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>i have to go clothes shopping tomorrow i hate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>i am bored any ideas of a nice site</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>i dont think will want to come back guys read ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>thomas if only the drinking game was tonighti ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            cleaned\n",
       "0          1              thats enough ill do nothing for hours\n",
       "1          0  i have to go clothes shopping tomorrow i hate ...\n",
       "2          1                i am bored any ideas of a nice site\n",
       "3          0  i dont think will want to come back guys read ...\n",
       "4          1  thomas if only the drinking game was tonighti ..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Removing Stopwords from the text\n",
    "\n",
    "Stop word is a commonly used word (such as “the”, “a”, “an”, “in”) that a search engine has been programmed to ignore, both when indexing entries for searching and when retrieving them as the result of a search query. \n",
    "We would not want these words to take up space in our database, or taking up valuable processing time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def remove_stopword(text):\n",
    "    stop_words = stopwords.words('english')\n",
    "    stopwords_dict = Counter(stop_words)\n",
    "    text = ' '.join([word for word in text.split() if word not in stopwords_dict])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenise(text):\n",
    "    words = word_tokenize(text) \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['cleaned']=df1['cleaned'].apply(lambda x: remove_stopword(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>thats enough ill nothing hours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>go clothes shopping tomorrow hate serious clot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>bored ideas nice site</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>dont think want come back guys read dms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>thomas drinking game tonighti dont work till t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            cleaned\n",
       "0          1                     thats enough ill nothing hours\n",
       "1          0  go clothes shopping tomorrow hate serious clot...\n",
       "2          1                              bored ideas nice site\n",
       "3          0            dont think want come back guys read dms\n",
       "4          1  thomas drinking game tonighti dont work till t..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tfidf Vectorizer:  In order to process natural language, the text must be represented as a numerical feature. The process of transforming text into a numerical feature is called text vectorization. TF-IDF is one of the most popular text vectorizers, the calculation is very simple and easy to understand. It gives the rare term high weight and gives the common term low weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(df1 ['cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df1[['sentiment']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling: Using SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oversampling the unbalanced data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "su = SMOTE(random_state=42)\n",
    "X_su, y_su = su.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    11117\n",
      "0    11117\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_su[\"sentiment\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building\n",
    "\n",
    "\n",
    "The three classifiers I have used are Naive Bayes, Logistic Regression and Gradient Boosting Classifier\n",
    "I went through various previous works and resources and got to know that the most commonly used classifiers for sentimental analysis are NB, Logistic Regression, SVM and GBM and XGBoost.\n",
    "\n",
    "The performance metrics used are:\n",
    "1. Confusion Matrix\n",
    "2. Precision, Recall and F1_score\n",
    "\n",
    "Cross Validation is done to check the robustness of the models\n",
    "Hyperparameter Tuning is done using GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the training set: 16675\n",
      "Number of rows in the test set: 5559\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# split into training and testing sets\n",
    "# USE from sklearn.model_selection import train_test_split to avoid seeing deprecation warning.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_su, \n",
    "                                                    y_su, \n",
    "                                                    random_state=1)\n",
    "\n",
    "\n",
    "print('Number of rows in the training set: {}'.format(x_train.shape[0]))\n",
    "print('Number of rows in the test set: {}'.format(x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Naive Bayes: 0.742\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.78      0.75      2814\n",
      "           1       0.75      0.71      0.73      2745\n",
      "\n",
      "    accuracy                           0.74      5559\n",
      "   macro avg       0.74      0.74      0.74      5559\n",
      "weighted avg       0.74      0.74      0.74      5559\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(x_train,y_train.values.ravel())\n",
    "print('Accuracy of Naive Bayes: {:.3f}'.format(naive_bayes.score(x_test, y_test)))\n",
    "predictions1= naive_bayes.predict(x_test)\n",
    "print(classification_report(y_test, predictions1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2183,  631],\n",
       "       [ 805, 1940]], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix,f1_score, precision_score,recall_score\n",
    "y_predict = naive_bayes.predict(x_test)\n",
    "confusion_matrix(y_test,y_predict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 75.46%\n",
      "Recall: 70.67%\n",
      "F1-score: 0.7417\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test,y_predict).ravel()\n",
    "f1_NB = f1_score(y_test, predictions1 ,average='micro')\n",
    "\n",
    "print(\"Precision: {:.2f}%\".format(100 * precision_score(y_test, y_predict)))\n",
    "print(\"Recall: {:.2f}%\".format(100 * recall_score(y_test, y_predict)))\n",
    "print('F1-score: {}'.format(np.round(f1_NB,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_Acc_NaiveBayes :  0.7240167793779373\n"
     ]
    }
   ],
   "source": [
    "#Cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "NB_accuracies = cross_val_score(estimator = naive_bayes, X = x_train, y = y_train.values.ravel(), cv = cv)\n",
    "print(\"Mean_Acc_NaiveBayes : \", NB_accuracies.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression: 0.735\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.68      0.72      2814\n",
      "           1       0.71      0.79      0.75      2745\n",
      "\n",
      "    accuracy                           0.74      5559\n",
      "   macro avg       0.74      0.74      0.73      5559\n",
      "weighted avg       0.74      0.74      0.73      5559\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "logreg = LogisticRegression(C=0.5,max_iter=150,n_jobs=10,random_state=None)\n",
    "logreg.fit(x_train,y_train.values.ravel())\n",
    "print('Accuracy of Logistic Regression: {:.3f}'.format(logreg.score(x_test, y_test)))\n",
    "predictions2= logreg.predict(x_test)\n",
    "print(classification_report(y_test, predictions2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1908,  906],\n",
       "       [ 567, 2178]], dtype=int64)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = logreg.predict(x_test)\n",
    "confusion_matrix(y_test,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 70.62%\n",
      "Recall: 79.34%\n",
      "F1-score: 0.7417\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test,y_predict).ravel()\n",
    "f1_LR = f1_score(y_test, predictions1 ,average='micro')\n",
    "\n",
    "print(\"Precision: {:.2f}%\".format(100 * precision_score(y_test, y_predict)))\n",
    "print(\"Recall: {:.2f}%\".format(100 * recall_score(y_test, y_predict)))\n",
    "print('F1-score: {}'.format(np.round(f1_LR,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_Acc_Logreg :  0.7295953039607905\n"
     ]
    }
   ],
   "source": [
    "#Cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "LR_accuracies = cross_val_score(estimator = logreg, X = x_train, y = y_train.values.ravel(), cv = cv)\n",
    "print(\"Mean_Acc_Logreg : \", LR_accuracies.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the GBM on test set: 0.751\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.72      0.75      2814\n",
      "           1       0.73      0.78      0.76      2745\n",
      "\n",
      "    accuracy                           0.75      5559\n",
      "   macro avg       0.75      0.75      0.75      5559\n",
      "weighted avg       0.75      0.75      0.75      5559\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "gbc = GradientBoostingClassifier(n_estimators=600, learning_rate=0.5, max_features=10, max_depth=10, random_state=0)\n",
    "gbc=gbc.fit(x_train, y_train.values.ravel())\n",
    "predictions3 =gbc.predict(x_test)\n",
    "print('Accuracy of the GBM on test set: {:.3f}'.format(gbc.score(x_test, y_test)))\n",
    "print(classification_report(y_test, predictions3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2035,  779],\n",
       "       [ 607, 2138]], dtype=int64)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = gbc.predict(x_test)\n",
    "confusion_matrix(y_test,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 73.29%\n",
      "Recall: 77.89%\n",
      "F1-score: 0.7417\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test,y_predict).ravel()\n",
    "f1_GBM = f1_score(y_test, predictions1 ,average='micro')\n",
    "\n",
    "print(\"Precision: {:.2f}%\".format(100 * precision_score(y_test, y_predict)))\n",
    "print(\"Recall: {:.2f}%\".format(100 * recall_score(y_test, y_predict)))\n",
    "print('F1-score: {}'.format(np.round(f1_GBM,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_Acc_Logreg :  0.7388895602174529\n"
     ]
    }
   ],
   "source": [
    "#Cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "GBM_accuracies = cross_val_score(estimator = gbc, X = x_train, y = y_train.values.ravel(), cv = cv)\n",
    "print(\"Mean_Acc_Logreg : \", GBM_accuracies.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 27 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\misja\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best Parameters are: {'learning_rate': 0.5, 'max_depth': 10, 'n_estimators': 500}\n",
      "The best score is: 0.7692961407718457\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter Tuning\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "p_test= {'learning_rate':[0.05,0.1,0.5], 'n_estimators':[100,250,500],'max_depth':[4,6,10]}\n",
    "\n",
    "tuning = GridSearchCV(estimator =GradientBoostingClassifier(min_samples_split=500, min_samples_leaf=1, subsample=1,max_features='sqrt', random_state=10), \n",
    "            param_grid = p_test, scoring='accuracy',n_jobs=4,cv=10,verbose=4)\n",
    "tuning.fit(x_train,y_train)\n",
    "\n",
    "print('The best Parameters are:',tuning.best_params_)\n",
    "print('The best score is:',tuning.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results and the evaluation metrics like precision and recall and accuracy can be improved by even better methods for data cleaning and pre\n",
    "processing techniques.\n",
    "\n",
    "1. Textblobs can be used to find the polarity of the sentiments.\n",
    "2. Using VADER SentimentIntensityAnalyser is also an option\n",
    "3. The pre trained NLP model BERT might give better results than the supervised learning classifiers in ML.\n",
    "4. WordDictionary based model can be used in which labeled n-corpus is formed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
